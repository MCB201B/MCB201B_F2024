{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b122c9e8-4a0f-4422-a93e-2d0a638e4789",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">4.2 Python Image Analysis</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 850px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ffc1b9-34ea-42b2-b587-c33f60d875a4",
   "metadata": {},
   "source": [
    "In this week's lecture, we went over how images are expressed as either 2D matrices (single channel) or 3D matrices (multi-channel or true-color) with each pixel as an element in the matrix containing a numerical value representing the intensity of light. We're all familiar with using ImageJ for analyzing images, but here, we'll use Python to perform many of the same analyses that we can do in ImageJ. If we have time, we can also make use of both ImageJ and Python to develop a pipeline for analyzing more complex data, such as our beating cardiomyocytes from MCB201A. \n",
    "\n",
    "<strong>Learning objectives:</strong>\n",
    "<ul>\n",
    "    <li>Understand how images are represented as a matrix</li>\n",
    "    <li>Learn how to import and display images in a Python notebook</li>\n",
    "    <li>Learn how to process images for analysis</li>\n",
    "    <li>Learn how to analyze images to extract quantitative data</li>\n",
    "    <li>Set up for loops and functions to analyze and plot a mulitple particles</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c6dc4-29bd-4947-839f-d2da11a0c86f",
   "metadata": {},
   "source": [
    "For today's lesson, we'll be making use of the following packages:\n",
    "<ul>\n",
    "    <li>numpy</li>\n",
    "    <li>pandas</li>\n",
    "    <li>matplotlib.pyplot - we will also use matplotlib to display our images</li>\n",
    "    <li><a href=\"https://scikit-image.org/\" rel=\"noopener noreferrer\" target=\"_blank\">scikit-image (skimage)</a> - a package with a suite of tools for image analysis in Python. We'll make use of the <mark style=\"background-color: #EEEEEE;\"><strong>skimage.measure</strong></mark> package and the <mark style=\"background-color: #EEEEEE;\"><strong>color</strong></mark> package as well as other packages later on if we have time</li>\n",
    "    <li>seaborn</li>\n",
    "    <li>scipy.stats</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85274533-847e-46f3-9be9-1aebf9932eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f84fcd93-4e08-4e27-a24a-9dfd17d1383f",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">Images as a matrix</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 600px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543734f-cd11-4268-9389-bbe72a32e3b3",
   "metadata": {},
   "source": [
    "As you recall from lecture, an 8-bit grayscale image can be represented as a 2D matrix containing values from 0 (black) to 255 (white).\n",
    "\n",
    "Let's set up a quick, random 2D array below and use <mark style=\"background-color: #EEEEEE;\"><strong>plt.imshow</strong></mark> to display our grayscale image. <a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html\" rel=\"noopener noreferrer\" target=\"_blank\"><u>Documentation for <mark style=\"background-color: #EEEEEE;\"><strong>plt.imshow</strong></mark> is here.</u></a>\n",
    "\n",
    "We can make use of our usual random integer generator <mark style=\"background-color: #EEEEEE;\"><strong>np.random.randint()</strong></mark>, but we will need to specify that we are working with 8-bit integers by setting the <mark style=\"background-color: #EEEEEE;\"><strong>dtype</strong></mark> parameter to <mark style=\"background-color: #EEEEEE;\"><strong>np.uint8</strong></mark>.\n",
    "```\n",
    "gray_img = np.random.randint(0, 256, size=[50,50], dtype=np.uint8)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d15f1-219a-4012-b4e8-3b3921167c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e7166b2-5ce4-49d0-a721-f9d69912e977",
   "metadata": {},
   "source": [
    "Now that we have our 2D array of pixel intensities, we can display our image using <mark style=\"background-color: #EEEEEE;\"><strong>plt.imshow</strong></mark>. However, we'll need to make some adjustments to the default parameters, so that we display our image as a grayscale image.\n",
    "\n",
    "We'll set the <mark style=\"background-color: #EEEEEE;\"><strong>cmap</strong></mark> parameter equal to <mark style=\"background-color: #EEEEEE;\"><strong>'gray'</strong></mark> to tell the function to display our image in grayscale. And we'll specify the bit-depth by providing it with the maximum and minimum values, corresponding to black and white respectively. To do this, we'll set <mark style=\"background-color: #EEEEEE;\"><strong>vmin</strong></mark> equal to 0 and <mark style=\"background-color: #EEEEEE;\"><strong>vmax</strong></mark> equal to 255. We can also hide our plot axes by setting it to <mark style=\"background-color: #EEEEEE;\"><strong>False</strong></mark> and suppressing further outputs in the line with a semicolon <mark style=\"background-color: #EEEEEE;\"><strong>;</strong></mark>, so we only display our plot.\n",
    "```\n",
    "plt.imshow(gray_img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.axis(False);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1af81-78c5-4e4b-bea4-1991e8ccc932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c80f39da-dbc1-46f9-9de5-c0931241de96",
   "metadata": {},
   "source": [
    "We can also do something similar for a true-color image. Let's create a 3-channel image using a similar set up that we used for our grayscale image. This time we will have 3 elements in the size object that we pass to our function in order to create a 3D array or random integers.\n",
    "```\n",
    "color_img = np.random.randint(0, 256, size=[50, 50, 3], dtype=np.uint8)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b3949-fd4f-4b3e-b4aa-b04884fb577d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "350a9c39-e677-4504-9141-b22d845f8a52",
   "metadata": {},
   "source": [
    "If we wanted to pull information from a specific channel, we can use slice notation to pull out either the red, green or blue channel.\n",
    "```\n",
    "red_color = color_img[:, :, 0]\n",
    "green_color = color_img[:, :, 1]\n",
    "blue_color = color_img[;, ;, 2]\n",
    "```\n",
    "\n",
    "What this means is that if we look along the third axis, we have 3 elements that are 2D arrays: <mark style=\"background-color: #EEEEEE;\"><strong>[red_color, green_color, blue_color]</strong></mark>. You'll want to keep this in mind for later when you are combining channels together or trying to pseudocolor a single channel because the order in which the 2D arrays are arranged along the third axis (channel axis) dictates their color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2e2e4-f850-4183-956b-aac3a9c570b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae8d786-a3cd-41e7-a5dc-b67b2aa1883f",
   "metadata": {},
   "source": [
    "Since each pixel is an element within our 2D matrix, we can also pull out sections of our images to perform analyses or to visualize the intensity profiles.\n",
    "```\n",
    "red_color_profile = red_color[25,:]\n",
    "green_color_profile = green_color[25,:]\n",
    "blue_color_profile = blue_color[25,:]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8884ba7-d860-4b0e-bcd8-4ce20246d394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93ab5948-c5d3-4c66-8cff-35bc7912a254",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">Exercise #1: Importing and displaying images</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 900px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8293f-c508-4961-8dd5-e2728f3718d4",
   "metadata": {},
   "source": [
    "Let's make use of our immunofluorescence data from MCB201A to do some image processing and then later today use it for image analysis. Upload three channels corresponding to a representative image of your serum starved cells (either YAP or TAZ) and (if you want) also a set of three channels for your serum stimulated cells. We'll import all of them and use the images to learn how to process images and analyze them to extract quantitative data from our images.\n",
    "\n",
    "To import images, we will use <mark style=\"background-color: #EEEEEE;\"><strong>plt.imread()</strong></mark>, which will turn our images into an array that we can play with using Python. <a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imread.html\" rel=\"noopener noreferrer\" target=\"_blank\"><u>Documentation for <mark style=\"background-color: #EEEEEE;\"><strong>plt.imread()</strong></mark> is here.</u></a>\n",
    "```\n",
    "variable = plt.imread('File_name.extension')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d7914-f505-43e6-8824-f017e4d9a4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcfc93-0a33-44c6-901b-8f312549ee38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eea9a03-ebb4-47d2-a44a-ac5b9688114c",
   "metadata": {},
   "source": [
    "Now let's take a look at our individual images side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e260956-01ae-42e3-8bfe-b91aab789d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e98c7d3b-3caf-49d3-ac22-e4bc017f3b22",
   "metadata": {},
   "source": [
    "<h2>Displaying images in color</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34121c5-356b-4529-8c58-16ce7565f043",
   "metadata": {},
   "source": [
    "If we want to display our images as a composite, we can construct a 3D array out of our separate 2D arrays by using the <mark style=\"background-color: #EEEEEE;\"><strong>np.dstack()</strong></mark> function, which will stack our arrays along the third axis. \n",
    "\n",
    "For <mark style=\"background-color: #EEEEEE;\"><strong>plt.imshow()</strong></mark>, the channels are defined in the order <mark style=\"background-color: #EEEEEE;\"><strong>[red, green, blue]</strong></mark> along the third axis of our 3D matrix. Recall from earlier that the third axis contains the channels, and the order in which they are positioned along the third axis dictates their assigned color. So when we construct the 3D matrix, we'll need to pay attention to the order in which we provide our 2D matrices.\n",
    "```\n",
    "composite = np.dstack((red_channel, green_channel, blue_channel))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdce56f-24e9-482f-ac73-e53629d41e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0470eb-ca3c-411d-988f-a8702112533f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a41df80b-955c-48da-97ef-c78a1627760c",
   "metadata": {},
   "source": [
    "If you're noticing a warning with your RGB image being displayed, you may need to normalize the intensity values by the maximum intensity value for each channel.\n",
    "```\n",
    "composite = np.dstack((red_channel/red_channel.max(), green_channel/green_channel.max(), blue_channel/blue_channel.max()))\n",
    "```\n",
    "This will scale your values between 0 and 1, allowing <mark style=\"background-color: #EEEEEE;\"><strong>plt.imshow()</strong></mark> to display your color image without the warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713b094-b2e6-4c72-b5be-1ed26f81ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc836ce-f070-44d9-9e21-bbfae767f8d0",
   "metadata": {},
   "source": [
    "If the image doesn't appear bright enough, you can also scale it with a value smaller than your max value, and the values that remain above 1 will be clipped to 1.\n",
    "```\n",
    "composite = np.dstack((red_channel/1500, green_channel/1500, blue_channel/1500))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9a9e3-cd42-463f-87ba-2264e7177e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59bffa57-4449-460e-9435-1414b9c6b96a",
   "metadata": {},
   "source": [
    "If instead, you wanted to pseudocolor a single channel a particular color, you'll need to specify which channel(s) you want your image to be displayed in. In this case, you'll need to construct a 3D matrix consisting of your 2D array repeated along all three channels. Then you can clear the channel(s) that you don't want, while leaving the one(s) that you want displayed.\n",
    "\n",
    "First, let's create a 3D matrix consisting of just our DAPI intensities.\n",
    "```\n",
    "Blue = np.dstack((blue_channel, blue_channel, blue_channel))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef73a2-c780-4d9c-974a-ce18233946bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f46ba1c9-a451-4582-99ba-a5e51c0db85d",
   "metadata": {},
   "source": [
    "Then, what we can do is to clear the channels that we don't want displayed and keep the blue channel. To do this, we can multiply our 3D matrix with a list containing three elements, with each element being either a 1 or 0 depending on whether or not we want to display a channel, leaving us with a 3D matrix that contains values only in the channel(s) we want displayed.\n",
    "```\n",
    "Blue_only = Blue*[0, 0, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0d2f9-2126-41aa-827c-6caa82ad9d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44c3bcdc-d154-4089-9bf1-a23d202373e4",
   "metadata": {},
   "source": [
    "Remember that screens follow the additive color model, so if we wanted a color like magenta or yellow, we would then make use of 2 channels rather than one.\n",
    "```\n",
    "Blue_as_magenta = Blue*[1, 0, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7deabf-9f5c-407d-a2f9-60fdf0a550d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1a09a-4295-479e-a614-fb4cfc86b731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b79a95ab-8c9f-4ed6-a998-42bef35e4e5d",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">Exercise #2: Adjust threshold to isolate nuclei</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 900px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c79436d-1d6c-4b76-af12-49f9ddc5b084",
   "metadata": {},
   "source": [
    "To identify a good threshold for us to use, we can take a look at the distribution of intensity values in our two nuclei images in a histogram. We will first need to collapse our 2D array into a single 1D array to make it easier to plot as a histogram by making use of the <mark style=\"background-color: #EEEEEE;\"><strong>numpy.ndarray.flatten()</strong></mark> function. <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html\" rel=\"noopener noreferrer\" target=\"_blank\"><u>Documentation is here.</u></a>.\n",
    "\n",
    "We can doing it simultaneously when we call up the histogram function:\n",
    "```\n",
    "sns.histplot(image_array.flatten(), bins=50)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd14f8-2678-419a-aa03-441527a6f799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "040bf3b0-69b8-422a-960b-c0f9ac872de6",
   "metadata": {},
   "source": [
    "Once you've identified a good spot to set as a threshold, you can apply a conditional statement to your DAPI images.\n",
    "```\n",
    "DAPI_thresh = DAPI_image > threshold\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a96d5c-03b4-40ea-b61e-2cb9b9d293c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fc76a-2275-4350-8cfa-846925093ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6113294-e2a5-45f2-add9-0893b4f46da8",
   "metadata": {},
   "source": [
    "Let's take a look at the data contained within our thresholded 2D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d3874-b558-4ffa-aff3-cc706293205c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20aca4e3-750a-4e3f-965a-f7bca7190072",
   "metadata": {},
   "source": [
    "You should be able to see now that your thresholded array contains Booleans. This is because we applied our conditional statement to each element in our 2D arrays, resulting in a Boolean output corresponding to whether or not each element in the array met that condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0775662-ed06-46f2-b8f3-46fbf667ee82",
   "metadata": {},
   "source": [
    "There are also many other ways to calculate thresholds. You can find additional information on how to use scikit-image to threshold your images <a href=\"https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_thresholding.html\" rel=\"noopener noreferrer\" target=\"_blank\"><u>here.</u></a> scikit-image can also test multiple thresholding algorithms at once, so you can see which one will best fit your specific processing needs. \n",
    "```\n",
    "from skimage import try_all_threshold\n",
    "\n",
    "fig, ax = try_all_threshold(your_image)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c66b98-08ea-464e-a5c6-f7d00ef29505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "971e3911-d878-4f19-a8b2-3e0679cb9fb9",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">Exercise #3: Pull quantitative data</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 650px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ece04-2913-4c3b-ae90-8323bd8a56a9",
   "metadata": {},
   "source": [
    "We can use the **scikit-image packages** that we imported earlier to pull quantitative data from our images, specifically, we are going to use it to identify individual particles in our image by using <mark style=\"background-color: #EEEEEE;\"><strong>skimage.measure.label()</strong></mark>. <a href=\"https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.label\" rel=\"noopener noreferrer\" target=\"_blank\"><u>Documentation is here.</u></a> \n",
    "\n",
    "The <mark style=\"background-color: #EEEEEE;\"><strong>skimage.measure.label()</strong></mark> function works by assigning any element with the value 0 as background (by default) and then identifying particles as clusters of connected elements that share the same value (in our case the value 1). Then it will assign each particle a label.\n",
    "```\n",
    "DAPI_thresh_label = skimage.measure.label(DAPI_thresh, return_num=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91adb3d-e6ec-4677-836f-88ca351b5bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b367b52e-f766-4589-b8bd-95cbdd6e54b7",
   "metadata": {},
   "source": [
    "Let's take a look at our labeled cells and differentiate them by assigning them each a color that they will display as. To do this, we'll need to make use of the <mark style=\"background-color: #EEEEEE;\"><strong>label2rgb()</strong></mark> function, which returns a colored image where each label has its own color. So in our case, each one of our nuclei will have its own color. <a href=\"https://scikit-image.org/docs/stable/api/skimage.color.html#skimage.color.label2rgb\" rel=\"noopener noreferrer\" target=\"_blank\"><u>Documentation for <mark style=\"background-color: #EEEEEE;\"><strong>label2rgb()</strong></mark> is here.</u></a>\n",
    "```\n",
    "colored_nuclei = label2rgb(DAPI_thresh_label)\n",
    "plt.imshow(colored_nuclei)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f79e2-f6ae-48bf-81ad-c45a3c3bc0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aab9095a-74c1-4584-9a38-f45e62fed561",
   "metadata": {},
   "source": [
    "With our labeled nuclei, we can make use of the <mark style=\"background-color: #EEEEEE;\"><strong>skimage.measure.regionprops()</strong></mark> function, which will measure a bunch of properties of each particle. <a href=\"https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops\" rel=\"noopener noreferrer\" target=\"_blank\"><u>Documentation for <mark style=\"background-color: #EEEEEE;\"><strong>skimage.measure.regionprops()</strong></mark>, including the full set of properties that it measures, can be found here.</u></a>\n",
    "```\n",
    "nuclei_properties = skimage.measure.regionprops(DAPI_thresh_label)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b617aee-5ce3-4df3-b408-98fc726ea108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f50cb37a-8e2e-4483-8b5a-d4cc5a22b207",
   "metadata": {},
   "source": [
    "Try printing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3fae8-6b1f-4a4a-a2db-c3f0e0e513a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c972b02-071d-47ae-aa66-6591288f4d2a",
   "metadata": {},
   "source": [
    "So what is going on? Let's pull out the first element to try and make sense of the output of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fcc392-ab65-477f-a8eb-0bed5155144e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "158a005e-7f9b-4772-b573-2c31a7b1eea6",
   "metadata": {},
   "source": [
    "What you can see is that the first element is some set of <mark style=\"background-color: #EEEEEE;\"><strong>RegionProperties</strong></mark>, and we can see from the documentation that we can access each property as an attribute.\n",
    "\n",
    "If we wanted to get the area for our first particle:\n",
    "```\n",
    "nuclei_properties[0].area\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1c23d-57a9-49ff-91e4-a0c5d67be8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97789ca6-85f9-4908-a82a-44516b1194b4",
   "metadata": {},
   "source": [
    "And the number of elements in this output corresponds to the number of particles that we labeled.\n",
    "```\n",
    "print(len(nuclei_properties))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f4850-5e79-48bd-bc24-c8935519b923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "734ee05a-1bf6-4fc5-8fde-20659396f1dc",
   "metadata": {},
   "source": [
    "You can see that the output is not something we can make sense of without digging into each element one by one, so that means we will need to initiate a for-loop in order to get all the output data for a particular property that we're interested in.\n",
    "\n",
    "For example, if we're interested in the area of our particles:\n",
    "```\n",
    "areas = []\n",
    "\n",
    "for i in nuclei_properties:\n",
    "     areas.append(i.area)\n",
    "```\n",
    "\n",
    "In this case, the iterable object that we provide is not just a simple list of <mark style=\"background-color: #EEEEEE;\"><strong>[0,1,2,3,4,5]</strong></mark>, but rather it will go through each element of the list which corresponds to the <mark style=\"background-color: #EEEEEE;\"><strong>RegionProperties</strong></mark> of each particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a000f-7617-4537-a5c8-705a8d6d6a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b881f72b-c206-44ca-ac0c-738f9577f39c",
   "metadata": {},
   "source": [
    "Let's take a look at the areas for our particles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708131a9-290b-4db2-a87a-54fae631e615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c660db7d-d05e-48d2-b4d4-b9a861c97ef2",
   "metadata": {},
   "source": [
    "So by using Python, we are able to extract quantitative the properties of our nuclei."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a78050-ea97-484e-a40a-58651b267633",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">Exercise #4: Filter out noise</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 650px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e204c62-7626-4334-95dc-f900fe12a2b8",
   "metadata": {},
   "source": [
    "Let's take a look at the distribution of our particle areas. This will help us see if we may have captured a lot of noise, and if we have noise, we can filter those \"particles\" out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe3eaa-0c1b-4c6b-bde9-3bf6a5ddd566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afbdff62-0280-4ebd-aacd-630adffed977",
   "metadata": {},
   "source": [
    "You can see that we have a fair number of tiny tiny particles with an area of less than 100 sq pixels, which probably correspond to noise and isn't something particularly interesting for us. So what we can do is apply a conditional statement to each of our particles based on whether or not their area is greater than what we consider noise.\n",
    "\n",
    "Since we're going through each property again, we'll need a for loop to make our way through each particle.\n",
    "\n",
    "```\n",
    "nuclei_filtered = np.zeros_like(labels)\n",
    "\n",
    "for i in nuclei_properties:\n",
    "    if i.area > 100:\n",
    "        nuclei_filtered = nuclei_filtered + (labels == i.label)\n",
    "\n",
    "plt.imshow(nuclei_filtered)\n",
    "```\n",
    "\n",
    "Here, we've made use of the <mark style=\"background-color: #EEEEEE;\"><strong>np.zeros_like()</strong></mark> function, which functions similarly to <mark style=\"background-color: #EEEEEE;\"><strong>np.zeros()</strong></mark>, except that it will create an array of zeros with the shape of the object that we give it. So this is a convenient way of creating arrays of zeros with a desired shape.\n",
    "\n",
    "Our for loop will again be working its way through each element in our <mark style=\"background-color: #EEEEEE;\"><strong>nuclei_properties</strong></mark> and checking the area to see if it meets our threshold for an actual nucleus, and once it meets that condition, it will update our array with the label values. Here, we're not pulling the specific label value for each element. Instead, since anything not labeled will be zero, we can add the label array to our array of zeros, and it will essentially clone that label over without erasing any previous labels that were added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d84bbb5-f9cf-430e-870a-adefab55957a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccc77b23-111c-4e7e-ad4b-fe32e7eebd01",
   "metadata": {},
   "source": [
    "Now we'll want to relabel our filtered cells, so that we can ignore the noise when we want to continue with our analysis.\n",
    "```\n",
    "nuclei_filtered_labels, number_labels = skimage.measure.label(nuclei_filtered, return_num=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c4d64-eae1-44e7-8526-8bf4667bbd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6b8d2af-3d66-48ce-a548-7b8fcc7bf87a",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">Exercise #5: Pull out a single cell</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 650px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58121e6-422c-406f-9de4-63b109aba27e",
   "metadata": {},
   "source": [
    "We can continue to make use of conditional statements to pull out a single cell by its label.\n",
    "```\n",
    "nuclei_1 = nuclei_filtered_labels == 1\n",
    "```\n",
    "This will create a new 2D array that pulls out the nucleus labeled as 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5e08a-844f-4a6d-974d-3d70acaeea86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d13b4605-ba8c-4622-8ae7-730af922c5b3",
   "metadata": {},
   "source": [
    "And if we take a look at the data type contained within the 2D array created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624b2ca-a112-4afc-ad8d-9608998d090f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10efe26c-de9e-42d6-b8c3-92a9917ec668",
   "metadata": {},
   "source": [
    "You can see that it is a 2D array containing Boolean values, and only where the cell label matches what we specified will it return <mark style=\"background-color: #EEEEEE;\"><strong>true</strong></mark>, which we can then visualize using <mark style=\"background-color: #EEEEEE;\"><strong>plt.imshow()</strong></mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc3d4b-214d-4086-a758-3de5feeec8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf05fcb6-c523-4958-be3d-8ec9e36d3e79",
   "metadata": {},
   "source": [
    "Since we have a handful of nuclei to plot, let's set up two separate for loops to plot out each individual nuclei side by side. The first for loop will be to pull out each nucleus, and the second for loop will be to plot them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90248ae3-0b16-445d-9f03-205117019b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6fbc050-9fb4-4441-8d2a-204f67f42418",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">Exercise #6: Quantify mean nuclear fluorescence</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 950px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4aa1f8-f583-47d6-a46b-ec860b18a0a0",
   "metadata": {},
   "source": [
    "With all of our nuclei filtered down to ones that are actually nuclei, we can then make use of another for loop to go through our labeled nuclei to calculate the mean nuclear fluorescence intensity of our transcription factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b057ddf-c718-404a-afc3-270fc626eab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4ab4adf-b379-4e44-b235-dff0d7543dfd",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">Challenge: Compare mean nuclear fluorescence</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 950px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472bbbb6-dddc-4524-9c30-7ef106a29565",
   "metadata": {},
   "source": [
    "Let's do the same for our serum-stimulated cells now, so we can compare the mean nuclear fluorescence intensity between serum-starved and serum-stimulated cells.\n",
    "\n",
    "For those of you who are more familiar with Python, see if you can define a function that will output the array of mean nuclear intensities for each cell and the mean of all nuclear intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5fda5-1666-4966-8c48-9c5dbc10fddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93a8dc5d-1305-47c6-8030-99885a8dd269",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 40px; margin-bottom: 0px;\">Challenge: Watershed (separate overlapping particles)</h1>\n",
    "\n",
    "<hr style=\"margin-left: 0px; border: 0.25px solid; border-color: #000000; width: 950px;\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159f4fd-78fc-431d-98b8-186d03ffd1ee",
   "metadata": {},
   "source": [
    "While there isn't a single function that will allow us to perform a watershed operation on overlapping particles, <a href=\"https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_watershed.html\" rel=\"noopener noreferrer\" target=\"_blank\"><u>we can take a look at the documentation in scikit-image to see how we can perform watershed segmentation.</u></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0dfce-c484-4764-bad1-0bdfc40a278c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b14afd23-5abc-4aa7-a516-2550d0637983",
   "metadata": {},
   "source": [
    "Then we can pull out specific segmented regions by their label and use that as a mask for our original threshold to separate the two overlapping nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327eb03-b992-48c4-8294-9a058d8cf744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ec96a-3538-4778-881f-674e578669ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
